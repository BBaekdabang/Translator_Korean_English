{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K57DXqZnmcQE"
      },
      "source": [
        "# 그래프에서 한글표현을 위해 폰트를 설치합니다.\n",
        "!apt-get update -qq\n",
        "!apt-get install fonts-nanum* -qq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFz9tEFJTIp1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d17d2d-84de-4f7d-a798-7a9924ead9f9"
      },
      "source": [
        "import matplotlib.pyplot as plt  # 그래프 그리는 용도\n",
        "import matplotlib.font_manager as fm  # 폰트 관련 용도\n",
        "path = '/usr/share/fonts/truetype/nanum/NanumGothicEco.ttf'  # 설치된 나눔글꼴중 원하는 녀석의 전체 경로를 가져오자\n",
        "font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
        "print(font_name)\n",
        "\n",
        "plt.rc('font', family=font_name)\n",
        "\n",
        "fm._rebuild()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NanumGothic Eco\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import urllib3\n",
        "import zipfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "cZw1fVIteaQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaMuDgAGeHSf"
      },
      "source": [
        "## Download the data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1V6HsBoEczDoo4NDZ1I5iXSfRxFxCatis"
      ],
      "metadata": {
        "id": "rRfJZZXhP7ZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2806ae7-4ecd-4f9f-b6da-b2886f7d6541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1V6HsBoEczDoo4NDZ1I5iXSfRxFxCatis\n",
            "To: /content/1_구어체(1).xlsx\n",
            "100% 15.8M/15.8M [00:00<00:00, 123MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1-Ar-wV5dhZAOALn-oa7uZ3eT6EKcepmh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkystSyPmYOI",
        "outputId": "ddbb7f85-0a9a-47f7-e309-a6918ca1ca6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-Ar-wV5dhZAOALn-oa7uZ3eT6EKcepmh\n",
            "To: /content/한영번역_타켓문장.csv\n",
            "100% 7.25k/7.25k [00:00<00:00, 7.61MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IQTEqtjeHSf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "a03e70c4-9ecb-42d0-8b96-6149c0e80be7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           SID                                                 원문  \\\n",
              "0            1  'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 ...   \n",
              "1            2                                       씨티은행에서 일하세요?   \n",
              "2            3              푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.   \n",
              "3            4   11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.   \n",
              "4            5     6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.   \n",
              "...        ...                                                ...   \n",
              "199995  199996                               나는 먼저 청소기로 바닥을 밀었어요.   \n",
              "199996  199997                             나는 먼저 팀 과제를 하고 놀러 갔어요.   \n",
              "199997  199998                              나는 비 같은 멋진 연예인을 좋아해요.   \n",
              "199998  199999                           나는 멋진 자연 경치를 보고 눈물을 흘렸어.   \n",
              "199999  200000                               나는 멋진 중학교 생활을 기대합니다.   \n",
              "\n",
              "                                                      번역문  \n",
              "0       Bible Coloring' is a coloring application that...  \n",
              "1                             Do you work at a City bank?  \n",
              "2       PURITO's bestseller, which recorded 4th rough ...  \n",
              "3       In Chapter 11 Jesus called Lazarus from the to...  \n",
              "4       I would feel grateful to know how many stocks ...  \n",
              "...                                                   ...  \n",
              "199995                First of all, I vacuumed the floor.  \n",
              "199996  I did the team assignment first and went out t...  \n",
              "199997                 I like cool entertainer like Rain.  \n",
              "199998                I cried seeing the amazing scenery.  \n",
              "199999  I look forward to a great middle school experi...  \n",
              "\n",
              "[200000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15ed525f-eef3-4322-85ba-712ee8d3b2af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>원문</th>\n",
              "      <th>번역문</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 ...</td>\n",
              "      <td>Bible Coloring' is a coloring application that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>씨티은행에서 일하세요?</td>\n",
              "      <td>Do you work at a City bank?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.</td>\n",
              "      <td>PURITO's bestseller, which recorded 4th rough ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.</td>\n",
              "      <td>In Chapter 11 Jesus called Lazarus from the to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.</td>\n",
              "      <td>I would feel grateful to know how many stocks ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>199996</td>\n",
              "      <td>나는 먼저 청소기로 바닥을 밀었어요.</td>\n",
              "      <td>First of all, I vacuumed the floor.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>199997</td>\n",
              "      <td>나는 먼저 팀 과제를 하고 놀러 갔어요.</td>\n",
              "      <td>I did the team assignment first and went out t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>199998</td>\n",
              "      <td>나는 비 같은 멋진 연예인을 좋아해요.</td>\n",
              "      <td>I like cool entertainer like Rain.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>199999</td>\n",
              "      <td>나는 멋진 자연 경치를 보고 눈물을 흘렸어.</td>\n",
              "      <td>I cried seeing the amazing scenery.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>200000</td>\n",
              "      <td>나는 멋진 중학교 생활을 기대합니다.</td>\n",
              "      <td>I look forward to a great middle school experi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15ed525f-eef3-4322-85ba-712ee8d3b2af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15ed525f-eef3-4322-85ba-712ee8d3b2af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15ed525f-eef3-4322-85ba-712ee8d3b2af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_excel('/content/1_구어체(1).xlsx')\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('/content/한영번역_타켓문장.csv')\n",
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YOkS4DtpmtJ0",
        "outputId": "f0908e05-ca0b-4f3e-81a5-59b81461e0ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        한글\n",
              "0              정리가 필요하겠네요.\n",
              "1        처음 만났을 때를 떠올려 보세요\n",
              "2         구썸남 인스타에 좋아요 누름.\n",
              "3        있었던 일을 차분히 생각해봐요.\n",
              "4    많이 찍다보면 조금씩 실력이 늘거예요.\n",
              "..                     ...\n",
              "195               조심히 오세요.\n",
              "196            잘 이겨내고 있네요.\n",
              "197             궁금할 수 있어요.\n",
              "198         안 사귀는 것보다 좋지요.\n",
              "199   작은것에 감사하는 마음을 가져보세요.\n",
              "\n",
              "[200 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a3004fd-99ee-4f71-9554-d169d9215bc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>한글</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>정리가 필요하겠네요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>처음 만났을 때를 떠올려 보세요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>구썸남 인스타에 좋아요 누름.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>있었던 일을 차분히 생각해봐요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>많이 찍다보면 조금씩 실력이 늘거예요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>조심히 오세요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>잘 이겨내고 있네요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>궁금할 수 있어요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>안 사귀는 것보다 좋지요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>작은것에 감사하는 마음을 가져보세요.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a3004fd-99ee-4f71-9554-d169d9215bc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a3004fd-99ee-4f71-9554-d169d9215bc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a3004fd-99ee-4f71-9554-d169d9215bc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWy5iZxheHSg"
      },
      "source": [
        "## Modeling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuration"
      ],
      "metadata": {
        "id": "_Ol2sq2Su2vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128  # Batch size for training.\n",
        "epochs = 50  # Number of epochs to train for.\n",
        "hidden_units = 256  # Latent dimensionality of the encoding space.\n",
        "embedding_dim = 64\n",
        "num_samples = 200000  # Number of samples to train on."
      ],
      "metadata": {
        "id": "B4n2cwSelBiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "6q_bXjSlu14L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sent):\n",
        "\n",
        "  sent = sent.lower()\n",
        "\n",
        "  # 단어와 구두점 사이에 공백을 만듭니다.\n",
        "  # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
        "  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
        "  sent = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z!.?]+\", r\" \", sent)\n",
        "\n",
        "  # 다수 개의 공백을 하나의 공백으로 치환\n",
        "  sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "  return sent\n",
        "\n",
        "\n",
        "def load_preprocessed_data():\n",
        "  encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "\n",
        "  for i in range(len(df_train)) :\n",
        "    src_line = df_train['원문'][i]\n",
        "    tar_line = df_train['번역문'][i]\n",
        "\n",
        "  # source 데이터 전처리\n",
        "    src_line = [w for w in preprocess_sentence(src_line).split()]\n",
        "    src_line = src_line\n",
        "\n",
        "    # target 데이터 전처리\n",
        "    tar_line = preprocess_sentence(tar_line)\n",
        "    tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]  # teacher forcing을 위한 정답셋 \n",
        "    tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "    encoder_input.append(src_line)\n",
        "    decoder_input.append(tar_line_in)\n",
        "    decoder_target.append(tar_line_out)\n",
        "\n",
        "    if i == num_samples - 1:\n",
        "      break\n",
        "              \n",
        "  return encoder_input, decoder_input, decoder_target"
      ],
      "metadata": {
        "id": "nZ1-npBdvJ4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 테스트\n",
        "kor_sent = u\"씨티은행에서 일하세요?\" # u = utf-8 깨지지 않게\n",
        "en_sent = u\"Do you work at a City bank?\"\n",
        "\n",
        "print('전처리 전 한국어 문장 :', kor_sent)\n",
        "print('전처리 후 한국어 문장 :',preprocess_sentence(kor_sent))\n",
        "print('전처리 전 영어 문장 :', en_sent)\n",
        "print('전처리 후 영어 문장 :', preprocess_sentence(en_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B2krUBIvbm9",
        "outputId": "3ffee845-5210-4a83-b3f0-ac514243f32f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 전 한국어 문장 : 씨티은행에서 일하세요?\n",
            "전처리 후 한국어 문장 : 씨티은행에서 일하세요 ?\n",
            "전처리 전 영어 문장 : Do you work at a City bank?\n",
            "전처리 후 영어 문장 : do you work at a city bank ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents_kor_in, sents_en_in, sents_en_out  = load_preprocessed_data()"
      ],
      "metadata": {
        "id": "77GAjhJNwpTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('인코더의 입력 :',sents_kor_in[:5])\n",
        "print('디코더의 입력 :',sents_en_in[:5])\n",
        "print('디코더의 레이블 :',sents_en_out[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3soQU2Wbw3Z-",
        "outputId": "4c4d421e-14fd-47ed-ef3c-5c24090ed87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더의 입력 : [['.', '앱입니다', '컬러링', '있는', '수', '할', '체험', '이야기를', '아름다운', '성경의', '은', 'coloring', 'bible'], ['?', '일하세요', '씨티은행에서'], ['.', '기록하였다', '완판을', '차', '입소문만으로', '해외에서', '베스트셀러는', '푸리토의'], ['.', '살리셨습니다', '가운데서', '자', '죽은', '불러내어', '무덤에서', '나사로를', '이번엔', '예수님이', '장에서는'], ['.', '감사하겠습니다', '알려주시면', '제게', '될지', '재입고', '더', '개나', '몇', '사이즈가', '.']]\n",
            "디코더의 입력 : [['<sos>', 'bible', 'coloring', 'is', 'a', 'coloring', 'application', 'that', 'allows', 'you', 'to', 'experience', 'beautiful', 'stories', 'in', 'the', 'bible', '.'], ['<sos>', 'do', 'you', 'work', 'at', 'a', 'city', 'bank', '?'], ['<sos>', 'purito', 's', 'bestseller', 'which', 'recorded', 'th', 'rough', 'cuts', 'by', 'words', 'of', 'mouth', 'from', 'abroad', '.'], ['<sos>', 'in', 'chapter', 'jesus', 'called', 'lazarus', 'from', 'the', 'tomb', 'and', 'raised', 'him', 'from', 'the', 'dead', '.'], ['<sos>', 'i', 'would', 'feel', 'grateful', 'to', 'know', 'how', 'many', 'stocks', 'will', 'be', 'secured', 'of', 'size', '.', 'and', '.']]\n",
            "디코더의 레이블 : [['bible', 'coloring', 'is', 'a', 'coloring', 'application', 'that', 'allows', 'you', 'to', 'experience', 'beautiful', 'stories', 'in', 'the', 'bible', '.', '<eos>'], ['do', 'you', 'work', 'at', 'a', 'city', 'bank', '?', '<eos>'], ['purito', 's', 'bestseller', 'which', 'recorded', 'th', 'rough', 'cuts', 'by', 'words', 'of', 'mouth', 'from', 'abroad', '.', '<eos>'], ['in', 'chapter', 'jesus', 'called', 'lazarus', 'from', 'the', 'tomb', 'and', 'raised', 'him', 'from', 'the', 'dead', '.', '<eos>'], ['i', 'would', 'feel', 'grateful', 'to', 'know', 'how', 'many', 'stocks', 'will', 'be', 'secured', 'of', 'size', '.', 'and', '.', '<eos>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어집합 만들기"
      ],
      "metadata": {
        "id": "Axd2wLe9gvNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국어\n",
        "tokenizer_kor = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_kor.fit_on_texts(sents_kor_in)\n",
        "\n",
        "# 인코더 데이터\n",
        "encoder_input = tokenizer_kor.texts_to_sequences(sents_kor_in)"
      ],
      "metadata": {
        "id": "39t-g1BrgqcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 영어\n",
        "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_en.fit_on_texts(sents_en_in)\n",
        "tokenizer_en.fit_on_texts(sents_en_out)\n",
        "\n",
        "# 디코더 데이터\n",
        "decoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
        "decoder_target = tokenizer_en.texts_to_sequences(sents_en_out)"
      ],
      "metadata": {
        "id": "DbAkLs-Mg0TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding"
      ],
      "metadata": {
        "id": "j64et9aShbop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = pad_sequences(encoder_input, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, padding='post')"
      ],
      "metadata": {
        "id": "zLWODtVIhTKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
        "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
        "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl-7xYOBhuKz",
        "outputId": "79b39827-5b31-4f9a-8ba8-a9c6020eded7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더의 입력의 크기(shape) : (200000, 31)\n",
            "디코더의 입력의 크기(shape) : (200000, 52)\n",
            "디코더의 레이블의 크기(shape) : (200000, 52)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(tokenizer_kor.word_index) + 1\n",
        "tar_vocab_size = len(tokenizer_en.word_index) + 1\n",
        "\n",
        "print(f\"한국어 단어 집합의 크기 : {src_vocab_size}, 영어 단어 집합의 크기 : {tar_vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AGlTHKdh14V",
        "outputId": "a1b8885d-7f71-40fd-b658-ac042bca5ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한국어 단어 집합의 크기 : 194067, 영어 단어 집합의 크기 : 35242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_to_index = tokenizer_kor.word_index  # word : idx\n",
        "index_to_src = tokenizer_kor.index_word  # idx : word\n",
        "tar_to_index = tokenizer_en.word_index # word : idx\n",
        "index_to_tar = tokenizer_en.index_word # idx : word"
      ],
      "metadata": {
        "id": "tPoYTLRqh__O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random"
      ],
      "metadata": {
        "id": "72zf79OSiF5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print('랜덤 시퀀스 :',indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_411fG-j8n0",
        "outputId": "dbb8a534-0d11-41e2-bbc7-357f312212cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 시퀀스 : [168591 173630  88507 ... 120449 117962 144573]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ],
      "metadata": {
        "id": "7TirRddnj_wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10% Data test"
      ],
      "metadata": {
        "id": "PTdeGOr5k5go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_val = int(num_samples*0.1)\n",
        "\n",
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "metadata": {
        "id": "cg_H09pykkNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
        "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
        "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
        "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
        "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
        "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDn7Vq5KlGLG",
        "outputId": "0477bcd1-69a7-4633-e061-6d48881b7073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 source 데이터의 크기 : (180000, 31)\n",
            "훈련 target 데이터의 크기 : (180000, 52)\n",
            "훈련 target 레이블의 크기 : (180000, 52)\n",
            "테스트 source 데이터의 크기 : (20000, 31)\n",
            "테스트 target 데이터의 크기 : (20000, 52)\n",
            "테스트 target 레이블의 크기 : (20000, 52)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "ZHk-KpCzwhaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "JmBsEtHglHhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder"
      ],
      "metadata": {
        "id": "r2JlE6fe4MAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# Embedding Layer\n",
        "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs)\n",
        "\n",
        "# Return_state = True\n",
        "# LSTM 층 2개 추가\n",
        "encoder_lstm1 = LSTM(hidden_units, return_sequences=True, return_state = True)\n",
        "encoder_lstm2 = LSTM(hidden_units, return_sequences=True, return_state = True)\n",
        "encoder_lstm3 = LSTM(hidden_units, return_state = True)\n",
        "\n",
        "# 은닉 상태와 셀 상태를 리턴\n",
        "# encoder_outputs, state_h, state_c =  encoder_lstm(enc_emb)\n",
        "x1 =  encoder_lstm1(enc_emb)\n",
        "x2 = encoder_lstm2(x1)\n",
        "encoder_outputs, state_h, state_c =  encoder_lstm3(x2)\n",
        "\n",
        "# 인코더의 은닉 상태와 셀 상태를 저장\n",
        "encoder_states = [state_h, state_c] "
      ],
      "metadata": {
        "id": "oom_Gq0blQJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder"
      ],
      "metadata": {
        "id": "Y03Y7Iwi48O8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Attention"
      ],
      "metadata": {
        "id": "4KzUblnRAjLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# Embedding Layer\n",
        "dec_emb_layer = Embedding(tar_vocab_size, hidden_units)\n",
        "\n",
        "# Embedding Result\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# Return_state = True, Return_sequences = True\n",
        "# LSTM 층 1개 추가\n",
        "decoder_lstm1 = LSTM(hidden_units, return_sequences=True, return_state = True)\n",
        "decoder_lstm2 = LSTM(hidden_units, return_sequences=True, return_state = True)\n",
        "\n",
        "# initial_state = encoder_states\n",
        "# decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = encoder_states)\n",
        "x = decoder_lstm1(dec_emb, initial_state = encoder_states)\n",
        "decoder_outputs, _, _ = decoder_lstm2(x)\n",
        "\n",
        "# Attention\n",
        "S_ = tf.concat([state_h[:, tf.newaxis, :], decoder_outputs[:, :-1, :]], axis=1) # query 만들기\n",
        "\n",
        "attention = Attention(hidden_units) # key, value 만들기\n",
        "context_vector, _ = attention([ S_, encoder_outputs], return_attention_scores = True) \n",
        "\n",
        "concat = tf.concat([decoder_outputs, context_vector], axis=-1)\n",
        "\n",
        "# Softmax\n",
        "decoder_dense = Dense(tar_vocab_size, activation = 'softmax')\n",
        "decoder_outputs = decoder_dense(concat)"
      ],
      "metadata": {
        "id": "Hi9cAZngThgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input / Output\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "MaIzBFFIsgmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EarlyStopping\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, mode = 'auto')"
      ],
      "metadata": {
        "id": "_zC3xjNv-nVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "#     monitor='val_loss', factor=0.1, patience=5, verbose=0, mode='auto',\n",
        "#     min_delta=0.0001, cooldown=0, min_lr=0)"
      ],
      "metadata": {
        "id": "RrW1C7h3q4Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size=128, epochs=50, callbacks = [early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRKB165fshn1",
        "outputId": "39ac54dc-a265-4fd9-e123-c1f990f06acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1407/1407 [==============================] - 377s 261ms/step - loss: 1.3236 - acc: 0.8130 - val_loss: 1.0705 - val_acc: 0.8370\n",
            "Epoch 2/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.9337 - acc: 0.8548 - val_loss: 0.8265 - val_acc: 0.8721\n",
            "Epoch 3/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.7197 - acc: 0.8843 - val_loss: 0.6678 - val_acc: 0.8937\n",
            "Epoch 4/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.5616 - acc: 0.9056 - val_loss: 0.5430 - val_acc: 0.9111\n",
            "Epoch 5/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.4422 - acc: 0.9222 - val_loss: 0.4534 - val_acc: 0.9257\n",
            "Epoch 6/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.3533 - acc: 0.9349 - val_loss: 0.3915 - val_acc: 0.9338\n",
            "Epoch 7/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.2858 - acc: 0.9448 - val_loss: 0.3538 - val_acc: 0.9399\n",
            "Epoch 8/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.2337 - acc: 0.9527 - val_loss: 0.3187 - val_acc: 0.9450\n",
            "Epoch 9/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.1912 - acc: 0.9598 - val_loss: 0.3019 - val_acc: 0.9474\n",
            "Epoch 10/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.1582 - acc: 0.9659 - val_loss: 0.2692 - val_acc: 0.9530\n",
            "Epoch 11/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.1320 - acc: 0.9711 - val_loss: 0.2673 - val_acc: 0.9530\n",
            "Epoch 12/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.1111 - acc: 0.9752 - val_loss: 0.2467 - val_acc: 0.9569\n",
            "Epoch 13/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0944 - acc: 0.9788 - val_loss: 0.2479 - val_acc: 0.9567\n",
            "Epoch 14/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0811 - acc: 0.9816 - val_loss: 0.2428 - val_acc: 0.9579\n",
            "Epoch 15/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0705 - acc: 0.9838 - val_loss: 0.2359 - val_acc: 0.9593\n",
            "Epoch 16/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0617 - acc: 0.9858 - val_loss: 0.2339 - val_acc: 0.9599\n",
            "Epoch 17/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0545 - acc: 0.9873 - val_loss: 0.2295 - val_acc: 0.9611\n",
            "Epoch 18/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0485 - acc: 0.9886 - val_loss: 0.2258 - val_acc: 0.9618\n",
            "Epoch 19/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0436 - acc: 0.9897 - val_loss: 0.2301 - val_acc: 0.9616\n",
            "Epoch 20/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0387 - acc: 0.9908 - val_loss: 0.2273 - val_acc: 0.9621\n",
            "Epoch 21/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0355 - acc: 0.9915 - val_loss: 0.2340 - val_acc: 0.9616\n",
            "Epoch 22/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0319 - acc: 0.9923 - val_loss: 0.2245 - val_acc: 0.9630\n",
            "Epoch 23/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0292 - acc: 0.9930 - val_loss: 0.2345 - val_acc: 0.9619\n",
            "Epoch 24/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0267 - acc: 0.9936 - val_loss: 0.2305 - val_acc: 0.9626\n",
            "Epoch 25/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0246 - acc: 0.9940 - val_loss: 0.2323 - val_acc: 0.9629\n",
            "Epoch 26/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0227 - acc: 0.9945 - val_loss: 0.2363 - val_acc: 0.9625\n",
            "Epoch 27/50\n",
            "1407/1407 [==============================] - 365s 260ms/step - loss: 0.0213 - acc: 0.9948 - val_loss: 0.2339 - val_acc: 0.9632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Translator_Training"
      ],
      "metadata": {
        "id": "GMarMK1Z5iJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 - 훈련과 동일 \n",
        "encoder_model = Model(encoder_inputs, [encoder_outputs, encoder_states])"
      ],
      "metadata": {
        "id": "Um7rlMm_WM4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더 \n",
        "\n",
        "# 이전 시점의 상태를 보관할 텐서\n",
        "decoder_state_input_h = Input(shape=(hidden_units,))\n",
        "decoder_state_input_c = Input(shape=(hidden_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "encoder_state_h = Input(shape=(hidden_units,))\n",
        "encoder_outputs2 = Input(shape =(None, hidden_units,))\n",
        "\n",
        "\n",
        "# 훈련 때 사용했던 임베딩 층을 재사용\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
        "decoder_outputs2, state_h, state_c = decoder_lstm2(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h, state_c]\n",
        "\n",
        "\n",
        "\n",
        "# Attention\n",
        "S_ = tf.concat([state_h[:, tf.newaxis, :], decoder_outputs2[:, :-1, :]], axis=1) # query \n",
        "\n",
        "context_vector, att_score = attention([decoder_outputs2, encoder_outputs2], return_attention_scores = True)\n",
        "decoder_concat = tf.concat([S_, context_vector], axis=-1)\n",
        "\n",
        "# 모든 시점에 대해서 단어 예측 (Fully Connected)\n",
        "decoder_outputs2 = decoder_dense(decoder_concat)\n",
        "\n",
        "# 수정된 디코더\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs, encoder_state_h, encoder_outputs2] + decoder_states_inputs,\n",
        "    [decoder_outputs2, att_score] + decoder_states2)"
      ],
      "metadata": {
        "id": "6birBiCUWOJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(sentence):\n",
        "  # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n",
        "  max_src_len, max_tar_len  = 15, 9\n",
        "\n",
        "  attention_plot = np.zeros((max_tar_len, max_src_len))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [tokenizer_kor.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_src_len,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  encoder_test, states_value = encoder_model.predict(inputs)\n",
        "\n",
        "  # <SOS>에 해당하는 정수 생성\n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0, 0] = tar_to_index['<sos>']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "\n",
        "  # stop_condition이 True가 될 때까지 루프 반복\n",
        "  # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
        "  for t in range(max_tar_len):\n",
        "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용                        ht\n",
        "    output_tokens, att_score, h, c = decoder_model.predict([target_seq, states_value[0], encoder_test] + states_value)\n",
        "\n",
        "    # 어텐션 가중치 시각화를 위해 저장 \n",
        "    att_score = tf.reshape(att_score, (-1, ))\n",
        "    attention_plot[t] = att_score.numpy() \n",
        "\n",
        "    # 예측 결과를 단어로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 단어를 예측 문장에 추가\n",
        "    decoded_sentence += ' '+sampled_char\n",
        "\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "    # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
        "    if sampled_char == '<eos>':\n",
        "        break \n",
        "\n",
        "  return sentence, decoded_sentence, attention_plot"
      ],
      "metadata": {
        "id": "ZNCPSMOGWaBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습과정에서의 정확도와 loss 히스토리를 시각화"
      ],
      "metadata": {
        "id": "tPTkFYs5ASvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "# early stopping epoch \n",
        "epochs_range = history.epoch\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L3iyUTHRomNq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}